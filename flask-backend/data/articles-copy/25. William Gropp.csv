Cites,Authors,Title,Year,Source,Publisher,ArticleURL,CitesURL,GSRank,QueryDate,Type,DOI,ISSN,CitationURL,Volume,Issue,StartPage,EndPage,ECC,CitesPerYear,CitesPerAuthor,AuthorCount,Age,Abstract
5607,"W Gropp, WD Gropp, E Lusk, A Skjellum, ADFEE Lusk","Using MPI: portable parallel programming with the message-passing interface",1999,"","books.google.com","https://books.google.com/books?hl=en&lr=&id=xpBZ0RyRb-oC&oi=fnd&pg=PA1&dq=%22william+gropp%22&ots=uchyo1LG6R&sig=HhzaZ-572sqXpPocSsrB3PmRiOw","https://scholar.google.com/scholar?cites=16190418257674977100&as_sdt=2005&sciodt=0,5&hl=en",1,"2020-05-04 21:11:13","BOOK","","","",,,,,5607,267.00,1121,5,21,"The Message Passing Interface (MPI) specification is widely used for solving significant scientific and engineering problems on parallel computers. There exist more than a dozen implementations on computer platforms ranging from IBM SP-2 supercomputers to clusters …"
3941,"M Snir, W Gropp, S Otto, S Huss-Lederman, J Dongarra…","MPI--the Complete Reference: the MPI core",1998,"","books.google.com","https://books.google.com/books?hl=en&lr=&id=x79puJ2YkroC&oi=fnd&pg=PR13&dq=%22william+gropp%22&ots=56ORpoUIG1&sig=nYP3_SWUKWWk8NIcdJVA67ywF3E","https://scholar.google.com/scholar?cites=4670580998788821020&as_sdt=2005&sciodt=0,5&hl=en",2,"2020-05-04 21:11:13","BOOK","","","",,,,,3941,179.14,657,6,22,"This volume, the definitive reference manual for the latest version of MPI-1, contains a complete specification of the MPI Standard. Since its release in summer 1994, the Message Passing Interface (MPI) specification has become a standard for message-passing libraries …"
2984,"W Gropp, E Lusk, N Doss, A Skjellum","A high-performance, portable implementation of the MPI message passing interface standard",1996,"Parallel computing","www-public.imtbs-tsp.eu","http://www-public.imtbs-tsp.eu/~gibson/Teaching/Teaching-ReadingMaterial/GroppLDS96.pdf","https://scholar.google.com/scholar?cites=12057140765855931724&as_sdt=2005&sciodt=0,5&hl=en",3,"2020-05-04 21:11:13","PDF","","","",,,,,2984,124.33,746,4,24,"Abstract MPI (Message Passing Interface) is a specification for a standard library for message passing that was defined by the MPI Forum, a broadly based group of parallel computer vendors, library writers, and applications specialists. Multiple implementations of …"
2789,"B Smith, P Bjorstad, W Gropp","Domain decomposition: parallel multilevel methods for elliptic partial differential equations",2004,"","books.google.com","https://books.google.com/books?hl=en&lr=&id=dxwRLu1dBioC&oi=fnd&pg=PR9&dq=%22william+gropp%22&ots=xSwJw-w2Cl&sig=ncZC_rDWO8QaL2v0R42af5mWoPY","https://scholar.google.com/scholar?cites=9982044766668117274&as_sdt=2005&sciodt=0,5&hl=en",4,"2020-05-04 21:11:13","BOOK","","","",,,,,2789,174.31,930,3,16,"This book presents an easy-to-read discussion of domain decomposition algorithms, their implementation and analysis. The relationship between domain decomposition and multigrid methods is carefully explained at an elementary level, and discussions of the …"
2023,"S Balay, WD Gropp, LC McInnes, BF Smith","Efficient management of parallelism in object-oriented numerical software libraries",1997,"Modern software tools for …","Springer","https://link.springer.com/chapter/10.1007/978-1-4612-1986-6_8","https://scholar.google.com/scholar?cites=15382187525277678671&as_sdt=2005&sciodt=0,5&hl=en",5,"2020-05-04 21:11:13","","","","",,,,,2023,87.96,506,4,23,"Parallel numerical software based on the message passing model is enormously complicated. This paper introduces a set of techniques to manage the complexity, while maintaining high efficiency and ease of use. The PETSc 2.0 package uses object-oriented …"
1221,"S Balay, S Abhyankar, MF Adams, J Brown, P Brune…","PETSc web page",2001,"","","","https://scholar.google.com/scholar?cites=307327545160929636&as_sdt=2005&sciodt=0,5&hl=en",6,"2020-05-04 21:11:13","CITATION","","","",,,,,1221,64.26,204,6,19,""
780,"W Gropp, R Thakur, E Lusk","Using MPI-2: Advanced features of the message passing interface",1999,"","dl.acm.org","https://dl.acm.org/citation.cfm?id=555150","https://scholar.google.com/scholar?cites=10417227124076488128&as_sdt=2005&sciodt=0,5&hl=en",8,"2020-05-04 21:11:13","BOOK","","","",,,,,780,37.14,260,3,21,"The Message Passing Interface (MPI) specification is widely used for solving significant scientific and engineering problems on parallel computers. There exist more than a dozen implementations on computer platforms ranging from IBM SP-2 supercomputers to clusters …"
750,"S Balay, K Buschelman, WD Gropp, D Kaushik…","PETSc web page, 2001",2004,"","","","https://scholar.google.com/scholar?cites=11495593464567755337&as_sdt=2005&sciodt=0,5&hl=en",7,"2020-05-04 21:11:13","CITATION","","","",,,,,750,46.88,150,5,16,""
704,"R Thakur, R Rabenseifner…","Optimization of collective communication operations in MPICH",2005,"The International Journal …","journals.sagepub.com","https://journals.sagepub.com/doi/abs/10.1177/1094342005051521?casa_token=96muChSsC4AAAAAA:qr17Ae0Zzr86U_8CwG5ANKTIEPbXCdKlxkUqFSzTiilyW8p3HNlvzBji_uoGGj3ca1BAUYKYJxf7VQ","https://scholar.google.com/scholar?cites=12500246606647733194&as_sdt=2005&sciodt=0,5&hl=en",9,"2020-05-04 21:11:13","","","","",,,,,704,46.93,235,3,15,"We describe our work on improving the performance of collective communication operations in MPICH for clusters connected by switched networks. For each collective operation, we use multiple algorithms depending on the message size, with the goal of minimizing latency …"
620,"R Thakur, W Gropp, E Lusk","Data sieving and collective I/O in ROMIO",1999,"Proceedings. Frontiers' 99 …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/750599/","https://scholar.google.com/scholar?cites=3369744499732618277&as_sdt=2005&sciodt=0,5&hl=en",10,"2020-05-04 21:11:13","","","","",,,,,620,29.52,207,3,21,"The I/O access patterns of parallel programs often consist of accesses to a large number of small, noncontiguous pieces of data. If an application's I/O needs are met by making many small, distinct I/O requests, however, the I/O performance degrades drastically. To avoid this …"
616,"J Dongarra, I Foster, G Fox, W Gropp, K Kennedy…","Sourcebook of parallel computing",2003,"","websrv.cs.fsu.edu","http://websrv.cs.fsu.edu/~mascagni/papers/RCEV2003_3.pdf","https://scholar.google.com/scholar?cites=9783760726897683918&as_sdt=2005&sciodt=0,5&hl=en",11,"2020-05-04 21:11:13","BOOK","","","",,,,,616,36.24,103,6,17,"Michael Mascagni Monte Carlo methods (MCMs) have been, and continue to be, very popular algorithms for solving a wide variety of problems in science, engineering, and technology. However, they are generally methods of last resort. As Mark Kác, a probability …"
581,"W Gropp, S Huss-Lederman, M Snir","MPI: the complete reference. The MPI-2 extensions",1998,"","books.google.com","https://books.google.com/books?hl=en&lr=&id=uK3nr41r8zMC&oi=fnd&pg=PA1&dq=%22william+gropp%22&ots=9pt1oPrCmz&sig=wczFau2aRhj6L13MdGbBE0tO0k0","https://scholar.google.com/scholar?cites=3233200576168962355&as_sdt=2005&sciodt=0,5&hl=en",12,"2020-05-04 21:11:13","BOOK","","","",,,,,581,26.41,194,3,22,"Since its release in summer 1994, the Message Passing Interface (MPI) specification has become a standard for message-passing libraries for parallel computations. There exist more than a dozen implementations on a variety of computing platforms, from the IBM SP-2 …"
449,"R Thakur, W Gropp, E Lusk","On implementing MPI-IO portably and with high performance",1999,"Proceedings of the sixth workshop on I/O in …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/301816.301826","https://scholar.google.com/scholar?cites=5201110147777813134&as_sdt=2005&sciodt=0,5&hl=en",13,"2020-05-04 21:11:13","","","","",,,,,449,21.38,150,3,21,"We discuss the issues involved in implementing MPI-IO portably on multiple machines and file systems and also achieving high performance. One way to implement MPI-IO portably is to implement it on top of the basic Unix I/O functions (open, lseek, read, write, and close) …"
414,"J Slotnick, A Khodadoust, J Alonso, D Darmofal…","CFD vision 2030 study: a path to revolutionary computational aerosciences",2014,"","ntrs.nasa.gov","https://ntrs.nasa.gov/search.jsp?R=20140003093","https://scholar.google.com/scholar?cites=6416507262354116973&as_sdt=2005&sciodt=0,5&hl=en",16,"2020-05-04 21:11:13","","","","",,,,,414,69.00,83,5,6,"This report documents the results of a study to address the long range, strategic planning required by NASA's Revolutionary Computational Aerosciences (RCA) program in the area of computational fluid dynamics (CFD), including future software and hardware requirements …"
409,"W Gropp, E Lusk","User's Guide for mpich, a Portable Implementation of MPI",1996,"","researchgate.net","https://www.researchgate.net/profile/Ewing_Lusk/publication/2807985_User's_Guide_for_mpich_a_Portable_Implementation_of_MPI/links/00463528aa8f280476000000.pdf","https://scholar.google.com/scholar?cites=546375858955200767&as_sdt=2005&sciodt=0,5&hl=en",15,"2020-05-04 21:11:13","PDF","","","",,,,,409,17.04,205,2,24,"Abstract MPI (Message-Passing Interface) is a standard speci cation for message-passing libraries. MPICH is a portable implementation of the full MPI speci cation for a wide variety of parallel and distributed computing environments. This paper describes how to build and run …"
408,"S Balay, WD Gropp, LC McInnes, BF Smith","PETSc 2.0 users manual",1996,"","mcs.anl.gov","http://ftp.mcs.anl.gov/pub/tech_reports/reports/ANL9511.pdf","https://scholar.google.com/scholar?cites=11901284358197686332&as_sdt=2005&sciodt=0,5&hl=en",14,"2020-05-04 21:11:13","PDF","","","",,,,,408,17.00,102,4,24,"This manual describes the use of PETSc 2.0 for the numerical solution of partial di erential equations and related problems on high-performance computers. The Portable, Extensible Toolkit for Scienti c Computation (PETSc) is a suite of data structures and routines that …"
386,"J Li, W Liao, A Choudhary, R Ross…","Parallel netCDF: A high-performance scientific I/O interface",2003,"SC'03: Proceedings …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1592942/","https://scholar.google.com/scholar?cites=14738931164737453364&as_sdt=2005&sciodt=0,5&hl=en",17,"2020-05-04 21:11:13","","","","",,,,,386,22.71,77,5,17,"Dataset storage, exchange, and access play a critical role in scientific applications. For such purposes netCDF serves as a portable, efficient file format and programming interface, which is popular in numerous scientific application domains. However, the original interface …"
339,"SS Baghsorkhi, M Delahaye, SJ Patel…","An adaptive performance modeling tool for GPU architectures",2010,"Proceedings of the 15th …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/1693453.1693470","https://scholar.google.com/scholar?cites=14843282561118621433&as_sdt=2005&sciodt=0,5&hl=en",18,"2020-05-04 21:11:13","","","","",,,,,339,33.90,85,4,10,"This paper presents an analytical model to predict the performance of general-purpose applications on a GPU architecture. The model is designed to provide performance information to an auto-tuning compiler and assist it in narrowing down the search to the …"
313,"S Balay, K Buschelman, WD Gropp, D Kaushik…","PETSc home page",2001,"","","","https://scholar.google.com/scholar?cites=8009534961244905424&as_sdt=2005&sciodt=0,5&hl=en",19,"2020-05-04 21:11:13","CITATION","","","",,,,,313,16.47,63,5,19,""
304,"F Cappello, G Al, W Gropp, S Kale, B Kramer…","Toward exascale resilience: 2014 update",2014,"… and Innovations: an …","dl.acm.org","https://dl.acm.org/doi/abs/10.14529/jsfi140101","https://scholar.google.com/scholar?cites=14506467815281971170&as_sdt=2005&sciodt=0,5&hl=en",23,"2020-05-04 21:11:13","HTML","","","",,,,,304,50.67,51,6,6,"Resilience is a major roadblock for HPC executions on future exascale systems. These systems will typically gather millions of CPU cores running up to a billion threads. Projections from current large systems and technology evolution predict errors will happen …"
296,"O Zaki, E Lusk, W Gropp…","Toward scalable performance visualization with Jumpshot",1999,"The International Journal …","journals.sagepub.com","https://journals.sagepub.com/doi/abs/10.1177/109434209901300310?casa_token=ey2ZNKGn3j4AAAAA:0KfcsJ1OMlklmSFW8PbKUltn6CSLwn-0ZAtE2C7Mqq1wxmF7XJzkfhIJeOp_NNlUd5W-NUYwv9TNww","https://scholar.google.com/scholar?cites=1089980636755065926&as_sdt=2005&sciodt=0,5&hl=en",22,"2020-05-04 21:11:13","","","","",,,,,296,14.10,74,4,21,"Jumpshot is a graphical tool for understanding the performance of parallel programs. It is in the tradition of the upshot tool but contains a number of extensions and enhancements that make it suitable for large-scale parallel computations. Jumpshot takes as input a new, more …"
294,"DE Keyes, WD Gropp","A comparison of domain decomposition techniques for elliptic partial differential equations and their parallel implementation",1987,"SIAM Journal on Scientific and Statistical Computing","SIAM","https://epubs.siam.org/doi/abs/10.1137/0908020","https://scholar.google.com/scholar?cites=7492298141193096818&as_sdt=2005&sciodt=0,5&hl=en",20,"2020-05-04 21:11:13","","","","",,,,,294,8.91,147,2,33,"Several preconditioned conjugate gradient (PCG)-based domain decomposition techniques for self-adjoint elliptic partial differential equations in two dimensions are compared against each other and against conventional PCG iterative techniques in serial and parallel …"
279,"R Thakur, WD Gropp","Improving the performance of collective operations in MPICH",2003,"… Parallel Virtual Machine/Message Passing Interface …","Springer","https://link.springer.com/chapter/10.1007/978-3-540-39924-7_38","https://scholar.google.com/scholar?cites=8316027701177248086&as_sdt=2005&sciodt=0,5&hl=en",21,"2020-05-04 21:11:13","","","","",,,,,279,16.41,140,2,17,"We report on our work on improving the performance of collective operations in MPICH on clusters connected by switched networks. For each collective operation, we use multiple algorithms depending on the message size, with the goal of minimizing latency for short …"
271,"DE Keyes, LC McInnes, C Woodward…","Multiphysics simulations: Challenges and opportunities",2013,"… Journal of High …","journals.sagepub.com","https://journals.sagepub.com/doi/abs/10.1177/1094342012468181","https://scholar.google.com/scholar?cites=5625879063498616706&as_sdt=2005&sciodt=0,5&hl=en",25,"2020-05-04 21:11:13","","","","",,,,,271,38.71,68,4,7,"We consider multiphysics applications from algorithmic and architectural perspectives, where “algorithmic” includes both mathematical analysis and computational complexity, and “architectural” includes both software and hardware environments. Many diverse …"
268,"W Gropp, E Lusk","Reproducible measurements of MPI performance characteristics",1999,"European Parallel Virtual Machine/Message Passing …","Springer","https://link.springer.com/chapter/10.1007/3-540-48158-3_2","https://scholar.google.com/scholar?cites=6923319803672042819&as_sdt=2005&sciodt=0,5&hl=en",24,"2020-05-04 21:11:13","","","","",,,,,268,12.76,134,2,21,"In this paper we describe the difficulties inherent in making accurate, reproducible measurements of message-passing performance. We describe some of the mistakes often made in attempting such measurements and the consequences of such mistakes. We …"
251,"W Gropp","MPICH2: A new start for MPI implementations",2002,"European Parallel Virtual Machine/Message Passing …","Springer","https://link.springer.com/chapter/10.1007/3-540-45825-5_5","https://scholar.google.com/scholar?cites=11897956113016260996&as_sdt=2005&sciodt=0,5&hl=en",26,"2020-05-04 21:11:13","","","","",,,,,251,13.94,251,1,18,"This talk will describe MPICH2, an all-new implementation of MPI designed to support both MPI-1 and MPI-2 and to enable further research into MPI implementation technology. To achieve high-performance and scalability and to encourage experimentation, the design of …"
232,"W Gropp, E Lusk","Fault tolerance in message passing interface programs",2004,"The International Journal of High …","journals.sagepub.com","https://journals.sagepub.com/doi/abs/10.1177/1094342004046045?casa_token=AjvKga7t5PEAAAAA:bVFyh3ozY97sgDLcTZ5kFk6u0E6jA3GPtWmvs7Uy218DBO3lHPhWQ9Yz9MclQ5vyIiJONwRmfX1NVg","https://scholar.google.com/scholar?cites=13550743514065771525&as_sdt=2005&sciodt=0,5&hl=en",28,"2020-05-04 21:11:13","","","","",,,,,232,14.50,116,2,16,"In this paper we examine the topic of writing fault-tolerant Message Passing Interface (MPI) applications. We discuss the meaning of fault tolerance in general and what the MPI Standard has to say about it. We survey several approaches to this problem, namely …"
230,"W Gropp, JJ Moré","Optimization Environments and the",1997,"… theory and optimization: tributes to MJD …","books.google.com","https://books.google.com/books?hl=en&lr=&id=IchVIe9AZk8C&oi=fnd&pg=PA167&dq=%22william+gropp%22&ots=pHxyNU_P6j&sig=fB6hk-2qmhqQeeu_9A4Dn-RZhIQ","https://scholar.google.com/scholar?cites=15744903060269412374&as_sdt=2005&sciodt=0,5&hl=en",30,"2020-05-04 21:11:13","","","","",,,,,230,10.00,115,2,23,"In an ideal computational environment the user would formulate the optimization problem and obtain results without worrying about computational resources. Unfortunately this ideal environment is not possible because if sufficient care is not given to the formulation, a …"
225,"R Thakur, W Gropp, E Lusk","An abstract-device interface for implementing portable parallel-I/O interfaces",1996,"… of 6th Symposium on the Frontiers …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/558080/","https://scholar.google.com/scholar?cites=8958594234331504578&as_sdt=2005&sciodt=0,5&hl=en",31,"2020-05-04 21:11:13","","","","",,,,,225,9.38,75,3,24,"We propose a strategy for implementing parallel I/O interfaces portably and efficiently. We have defined an abstract device interface for parallel I/O, called ADIO. Any parallel I/O API can be implemented on multiple file systems by implementing the API portably on top of …"
217,"WD Gropp, HG Kaper, GK Leaf, DM Levine…","Numerical simulation of vortex dynamics in type-II superconductors",1996,"Journal of …","Elsevier","https://www.sciencedirect.com/science/article/pii/S0021999196900224","https://scholar.google.com/scholar?cites=12730627758118154144&as_sdt=2005&sciodt=0,5&hl=en",29,"2020-05-04 21:11:13","","","","",,,,,217,9.04,43,5,24,"This article describes the results of several numerical simulations of vortex dynamics in type-II superconductors. The underlying mathematical model is the time-dependent Ginzburg–Landau model. The simulations concern vortex penetration in the presence of twin …"
214,"R Thakur, E Lusk, W Gropp","Users guide for ROMIO: A high-performance, portable MPI-IO implementation",1997,"","osti.gov","https://www.osti.gov/biblio/564273","https://scholar.google.com/scholar?cites=13559203675548208238&as_sdt=2005&sciodt=0,5&hl=en",33,"2020-05-04 21:11:13","","","","",,,,,214,9.30,71,3,23,"ROMIO is a high-performance, portable implementation of MPI-IO (the I/O chapter in MPI-2). This document describes how to install and use ROMIO version 1.0. 0 on the following machines: IBM SP; Intel Paragon; HP/Convex Exemplar; SGI Origin 2000, Challenge, and …"
211,"A Geist, W Gropp, S Huss-Lederman…","MPI-2: Extending the message-passing interface",1996,"… Conference on Parallel …","Springer","https://link.springer.com/chapter/10.1007/3-540-61626-8_16","https://scholar.google.com/scholar?cites=2548952191907683342&as_sdt=2005&sciodt=0,5&hl=en",27,"2020-05-04 21:11:13","","","","",,,,,211,8.79,53,4,24,"This paper describes current activities of the MPI-2 Forum. The MPI-2 Forum is a group of parallel computer vendors, library writers, and application specialists working together to define a set of extensions to MPI (Message Passing Interface). MPI was defined by the same …"
204,"L Greengard, WD Gropp","A parallel version of the fast multipole method",1990,"Computers & Mathematics with Applications","Elsevier","https://www.sciencedirect.com/science/article/pii/089812219090349O","https://scholar.google.com/scholar?cites=9803677744032890280&as_sdt=2005&sciodt=0,5&hl=en",32,"2020-05-04 21:11:13","","","","",,,,,204,6.80,102,2,30,"This paper presents a parallel version of the fast multipole method (FMM). The FMM is a recently developed scheme for the evaluation of the potential and force fields in systems of particles whose interactions are Coulombic or gravitational in nature. The sequential method …"
191,"NT Karonis, BR De Supinski, I Foster…","Exploiting hierarchy in parallel computer networks to optimize collective operation performance",2000,"Proceedings 14th …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/846009/","https://scholar.google.com/scholar?cites=8203534996813384547&as_sdt=2005&sciodt=0,5&hl=en",35,"2020-05-04 21:11:13","","","","",,,,,191,9.55,48,4,20,"The efficient implementation of collective communication operations has received much attention. Initial efforts modeled network communication and produced"" optimal"" trees based on those models. However, the models used by these initial efforts assumed equal point-to …"
186,"WD Gropp, DK Kaushik, DE Keyes, BF Smith","High-performance parallel implicit CFD",2001,"Parallel Computing","Elsevier","https://www.sciencedirect.com/science/article/pii/S0167819100000752","https://scholar.google.com/scholar?cites=3083416741851650683&as_sdt=2005&sciodt=0,5&hl=en",34,"2020-05-04 21:11:13","","","","",,,,,186,9.79,47,4,19,"Fluid dynamical simulations based on finite discretizations on (quasi-) static grids scale well in parallel, but execute at a disappointing percentage of per-processor peak floating point operation rates without special attention to layout and access ordering of data. We document …"
168,"S Byna, Y Chen, XH Sun, R Thakur…","Parallel I/O prefetching using MPI file caching and I/O signatures",2008,"SC'08: Proceedings of …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/5213604/","https://scholar.google.com/scholar?cites=6499316608244400267&as_sdt=2005&sciodt=0,5&hl=en",36,"2020-05-04 21:11:13","","","","",,,,,168,14.00,34,5,12,"Parallel I/O prefetching is considered to be effective in improving I/O performance. However, the effectiveness depends on determining patterns among future I/O accesses swiftly and fetching data in time, which is difficult to achieve in general. In this study, we propose an I/O …"
157,"XC Cai, WD Gropp, DE Keyes, RG Melvin…","Parallel Newton--Krylov--Schwarz algorithms for the transonic full potential equation",1998,"SIAM Journal on Scientific …","SIAM","https://epubs.siam.org/doi/abs/10.1137/S1064827596304046","https://scholar.google.com/scholar?cites=12835748194226933416&as_sdt=2005&sciodt=0,5&hl=en",37,"2020-05-04 21:11:13","","","","",,,,,157,7.14,31,5,22,"We study parallel two-level overlapping Schwarz algorithms for solving nonlinear finite element problems, in particular, for the full potential equation of aerodynamics discretized in two dimensions with bilinear elements. The overall algorithm, Newton--Krylov--Schwarz …"
149,"G Wilson, P Lu, W Gropp, E Lusk","Parallel programming using C++",1996,"","books.google.com","https://books.google.com/books?hl=en&lr=&id=n3kA3FzBTnEC&oi=fnd&pg=PR25&dq=%22william+gropp%22&ots=__IguFfMkB&sig=39raypgslyG2jr75ZRhRFVQMQxI","https://scholar.google.com/scholar?cites=1295246885325944306&as_sdt=2005&sciodt=0,5&hl=en",39,"2020-05-04 21:11:13","BOOK","","","",,,,,149,6.21,37,4,24,"Foreword by Bjarne Stroustrup Software is generally acknowledged to be the single greatest obstacle preventing mainstream adoption of massively-parallel computing. While sequential applications are routinely ported to platforms ranging from PCs to mainframes, most parallel …"
146,"DC Chan, SY Sim, R Thakur, T Isaacson…","Method and apparatus for real-time parallel delivery of segments of a large payload file",2006,"US Patent …","Google Patents","https://patents.google.com/patent/US7076553B2/en","https://scholar.google.com/scholar?cites=1014929203616438661&as_sdt=2005&sciodt=0,5&hl=en",38,"2020-05-04 21:11:13","","","","",,,,,146,10.43,29,5,14,"A scalable content delivery network (SCDN) employs a parallel download mechanism to ensure that a demanded file is present at a station in time for user consumption. This mechanism is used in solving the content caching and storage problem for applications such …"
143,"S Balay, S Abhyankar, MF Adams, J Brown, P Brune…","PETSc users manual (Tech. Rep. ANL-95/11-Revision 3.7)",2016,"Argonne National …","","","https://scholar.google.com/scholar?cites=5902888984455313142&as_sdt=2005&sciodt=0,5&hl=en",40,"2020-05-04 21:11:13","CITATION","","","",,,,,143,35.75,24,6,4,""
141,"D Buntinas, G Mercier, W Gropp","Design and evaluation of Nemesis, a scalable, low-latency, message-passing communication subsystem",2006,"Sixth IEEE International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1630865/","https://scholar.google.com/scholar?cites=15858846516242972874&as_sdt=2005&sciodt=0,5&hl=en",43,"2020-05-04 21:11:13","","","","",,,,,141,10.07,47,3,14,"This paper presents a new low-level communication subsystem called Nemesis. Nemesis has been designed and implemented to be scalable and efficient both in the intranode communication context using shared-memory and in the internode communication case …"
140,"WK Anderson, WD Gropp, DK Kaushik…","Achieving high sustained performance in an unstructured mesh CFD application",1999,"Proceedings of the …","dl.acm.org","https://dl.acm.org/doi/pdf/10.1145/331532.331600","https://scholar.google.com/scholar?cites=8021100073478780277&as_sdt=2005&sciodt=0,5&hl=en",41,"2020-05-04 21:11:13","PDF","","","",,,,,140,6.67,35,4,21,"Many applications of economic and national security importance require the solution of nonlinear partial differential equations (PDEs). In many cases, PDEs possess a wide range of time scales—some (eg, acoustic) faster than the phenomena of prime interest (eg …"
139,"I Foster, J Geisler, W Gropp, N Karonis, E Lusk…","Wide-area implementation of the message passing interface",1998,"Parallel Computing","Elsevier","https://www.sciencedirect.com/science/article/pii/S0167819198000751","https://scholar.google.com/scholar?cites=9118488794604589055&as_sdt=2005&sciodt=0,5&hl=en",42,"2020-05-04 21:11:13","","","","",,,,,139,6.32,23,6,22,"Abstract The Message Passing Interface (MPI) can be used as a portable, high-performance programming model for wide-area computing systems. The wide-area environment introduces challenging problems for the MPI implementor, due to the heterogeneity of both …"
130,"P Balaji, D Buntinas, D Goodell, W Gropp…","MPI on a Million Processors",2009,"… Parallel Virtual Machine …","Springer","https://link.springer.com/chapter/10.1007/978-3-642-03770-2_9","https://scholar.google.com/scholar?cites=6039856332015965790&as_sdt=2005&sciodt=0,5&hl=en",45,"2020-05-04 21:11:13","","","","",,,,,130,11.82,26,5,11,"Petascale machines with close to a million processors will soon be available. Although MPI is the dominant programming model today, some researchers and users wonder (and perhaps even doubt) whether MPI will scale to such large processor counts. In this paper …"
129,"WD Gropp, DK Kaushik, DE Keyes, BF Smith","Toward realistic performance bounds for implicit CFD codes",1999,"Proceedings of parallel …","Citeseer","http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.640.5489&rep=rep1&type=pdf","https://scholar.google.com/scholar?cites=2571248996735926208&as_sdt=2005&sciodt=0,5&hl=en",44,"2020-05-04 21:11:13","PDF","","","",,,,,129,6.14,32,4,21,"The performance of scientific computing applications often achieves a small fraction of peak performance [7, 17]. In this paper, we discuss two causes of performance problems—insufficient memory bandwidth and a suboptimal instruction mix—in the context of a …"
129,"R Thakur, W Gropp, E Lusk","Optimizing noncontiguous accesses in MPI–IO",2002,"Parallel Computing","Elsevier","https://www.sciencedirect.com/science/article/pii/S0167819101001296","https://scholar.google.com/scholar?cites=14162334471115907243&as_sdt=2005&sciodt=0,5&hl=en",46,"2020-05-04 21:11:13","","","","",,,,,129,7.17,43,3,18,"The I/O access patterns of many parallel applications consist of accesses to a large number of small, noncontiguous pieces of data. If an application's I/O needs are met by making many small, distinct I/O requests, however, the I/O performance degrades drastically. To avoid this …"
128,"J Liu, W Jiang, P Wyckoff, DK Panda…","Design and Implementation of MPICH2 over InfiniBand with RDMA Support",2004,"18th International …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1302922/","https://scholar.google.com/scholar?cites=8323200087597851615&as_sdt=2005&sciodt=0,5&hl=en",47,"2020-05-04 21:11:13","","","","",,,,,128,8.00,26,5,16,"Summary form only given. For several years, MPI has been the de facto standard for writing parallel applications. One of the most popular MPI implementations is MPICH. Its successor, MPICH2, features a completely new design that provides more performance and flexibility …"
123,"W Gropp, R Thakur","MPI-2: Advanced Features of the Message Passing Interface",1999,"","MIT Press, Cambridge, MA","","https://scholar.google.com/scholar?cites=7113726978011484259&as_sdt=2005&sciodt=0,5&hl=en",48,"2020-05-04 21:11:13","CITATION","","","",,,,,123,5.86,62,2,21,""
114,"XC Cai, WD Gropp, DE Keyes, MD Tidriri","Newton-Krylov-Schwarz methods in CFD",1994,"Numerical methods for the …","Springer","https://link.springer.com/chapter/10.1007/978-3-663-14007-8_3","https://scholar.google.com/scholar?cites=17572146983394525182&as_sdt=2005&sciodt=0,5&hl=en",49,"2020-05-04 21:11:13","","","","",,,,,114,4.38,29,4,26,"Newton-Krylov methods are potentially well suited for the implicit solution of nonlinear problems whenever it is unreasonable to compute or store a true Jacobian. Krylov-Schwarz iterative methods are well suited for the parallel implicit solution of multidimensional systems …"
111,"CE Wu, A Bolmarcich, M Snir, D Wootton…","From trace generation to visualization: A performance framework for distributed parallel systems",2000,"SC'00: Proceedings …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1592763/","https://scholar.google.com/scholar?cites=10145195598621000137&as_sdt=2005&sciodt=0,5&hl=en",50,"2020-05-04 21:11:13","","","","",,,,,111,5.55,22,5,20,"In this paper we describe a trace analysis framework, from trace generation to visualization. It includes a unified tracing facility on IBMâ SPä systems, a self-defining interval file format, an API for framework extensions, utilities for merging and statistics generation, and a …"
110,"R Thakur, W Gropp, E Lusk","A case for using MPI's derived datatypes to improve I/O performance",1998,"SC'98: Proceedings of the 1998 …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1437288/","https://scholar.google.com/scholar?cites=2692360047302546975&as_sdt=2005&sciodt=0,5&hl=en",51,"2020-05-04 21:11:13","","","","",,,,,110,5.00,37,3,22,"MPI-IO, the I/O part of the MPI-2 standard, is a promising new interface for parallel I/O. A key feature of MPI-IO is that it allows users to access several noncontiguous pieces of data from a file with a single I/O function call by defining file views with derived datatypes. We explain …"
110,"W Gropp, T Hoefler, R Thakur, E Lusk","Using advanced MPI: Modern features of the message-passing interface",2014,"","books.google.com","https://books.google.com/books?hl=en&lr=&id=GY5IBQAAQBAJ&oi=fnd&pg=PR7&dq=%22william+gropp%22&ots=lI6Vl3jURU&sig=U9DLupRa3oNleq4Dg7HPAXC6Uk0","https://scholar.google.com/scholar?cites=18022347866458241408&as_sdt=2005&sciodt=0,5&hl=en",55,"2020-05-04 21:11:13","BOOK","","","",,,,,110,18.33,28,4,6,"A guide to advanced features of MPI, reflecting the latest version of the MPI standard, that takes an example-driven, tutorial approach. This book offers a practical guide to the advanced features of the MPI (Message-Passing Interface) standard library for writing …"
108,"W Gropp, D Keyes, LC Mcinnes…","Globalized Newton-Krylov-Schwarz algorithms and software for parallel implicit CFD",2000,"… International Journal of …","journals.sagepub.com","https://journals.sagepub.com/doi/abs/10.1177/109434200001400202?casa_token=zRNSKIDo4iAAAAAA:nu8eGVG_kkIdX2qWCojTAWI7ITIhUtrIaN_SoZdGThJXXfii4rUEUXR0ijm3lwOdSCfd1mZ5U3Tk8Q","https://scholar.google.com/scholar?cites=1534002205144243196&as_sdt=2005&sciodt=0,5&hl=en",52,"2020-05-04 21:11:13","","","","",,,,,108,5.40,27,4,20,"Implicit solution methods are important in applications modeled by PDEs with disparate temporal and spatial scales. Because such applications require high resolution with reasonable turnaround, parallelization is essential. The pseudo-transient matrix-free Newton …"
108,"W Gropp, E Lusk, R Thakur","Using mpi-2",1999,"Using MPI","","","https://scholar.google.com/scholar?cites=15940980612148809563&as_sdt=2005&sciodt=0,5&hl=en",53,"2020-05-04 21:11:13","CITATION","","","",,,,,108,5.14,36,3,21,""
104,"A Ching, A Choudhary, W Liao, R Ross…","Noncontiguous i/o through pvfs",2002,"… on Cluster Computing","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1137773/","https://scholar.google.com/scholar?cites=10575684122661023067&as_sdt=2005&sciodt=0,5&hl=en",54,"2020-05-04 21:11:13","","","","",,,,,104,5.78,21,5,18,"With the tremendous advances in processor and memory technology, I/O has risen to become the bottleneck in high-performance computing for many applications. The development of parallel file systems has helped to ease the performance gap, but I/O still …"
103,"W Jiang, J Liu, HW Jin, DK Panda…","High performance MPI-2 one-sided communication over InfiniBand",2004,"… Computing and the …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1336648/","https://scholar.google.com/scholar?cites=3776777441403579545&as_sdt=2005&sciodt=0,5&hl=en",56,"2020-05-04 21:11:13","","","","",,,,,103,6.44,21,5,16,"Many existing MPI-2 one-sided communication implementations are built on top of MPI send/receive operations. Although this approach can achieve good portability, it suffers front high communication overhead and dependency on remote process for communication …"
103,"W Gropp, E Lusk, A Skjellum","Using MPI: Portable Programming with the Message-Passing Interface",1999,"Using MPI: Portable …","adsabs.harvard.edu","http://adsabs.harvard.edu/abs/1999umpi.book.....G","https://scholar.google.com/scholar?cites=5226922533019185088&as_sdt=2005&sciodt=0,5&hl=en",57,"2020-05-04 21:11:13","CITATION","","","",,,,,103,4.90,34,3,21,""
100,"N Galbreath, W Gropp, D Levine","Applications-driven parallel I/O",1993,"… '93: Proceedings of the 1993 …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1263494/","https://scholar.google.com/scholar?cites=13409621409881625970&as_sdt=2005&sciodt=0,5&hl=en",58,"2020-05-04 21:11:13","","","","",,,,,100,3.70,33,3,27,"The authors investigate the needs of some massively parallel applications running on distributed-memory parallel computers at Argonne National Laboratory and identify some common parallel I/O operations. For these operations, routines were developed that hide the …"
98,"D Buntinas, G Mercier, W Gropp","Implementation and evaluation of shared-memory communication and synchronization operations in MPICH2 using the Nemesis communication subsystem",2007,"Parallel Computing","Elsevier","https://www.sciencedirect.com/science/article/pii/S0167819107000786","https://scholar.google.com/scholar?cites=5442274279658624980&as_sdt=2005&sciodt=0,5&hl=en",59,"2020-05-04 21:11:13","","","","",,,,,98,7.54,33,3,13,"This paper presents the implementation of MPICH2 over the Nemesis communication subsystem and the evaluation of its shared-memory performance. We describe design issues as well as some of the optimization techniques we employed. We conducted a …"
94,"A Ching, A Choudhary, K Coloma…","Noncontiguous i/o accesses through mpi-io",2003,"CCGrid 2003. 3rd …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1199358/","https://scholar.google.com/scholar?cites=4987018501434540994&as_sdt=2005&sciodt=0,5&hl=en",60,"2020-05-04 21:11:13","","","","",,,,,94,5.53,24,4,17,"I/O performance remains a weakness of parallel computing systems today. While this weakness is partly attributed to rapid advances in other system components, I/O interfaces available to programmers and the I/O methods supported by file systems have traditionally …"
94,"T Hoefler, J Dinan, D Buntinas, P Balaji, B Barrett…","MPI+ MPI: a new hybrid approach to parallel programming with MPI plus shared memory",2013,"Computing","Springer","https://link.springer.com/article/10.1007/s00607-013-0324-2","https://scholar.google.com/scholar?cites=17593654669142522562&as_sdt=2005&sciodt=0,5&hl=en",61,"2020-05-04 21:11:13","","","","",,,,,94,13.43,16,6,7,"Hybrid parallel programming with the message passing interface (MPI) for internode communication in conjunction with a shared-memory programming model to manage intranode parallelism has become a dominant approach to scalable parallel programming …"
91,"A Chan, W Gropp, E Lusk","An efficient format for nearly constant-time access to arbitrary time intervals in large trace files",2008,"Scientific Programming","hindawi.com","https://www.hindawi.com/journals/sp/2008/749874/abs/","https://scholar.google.com/scholar?cites=5448751231567645250&as_sdt=2005&sciodt=0,5&hl=en",63,"2020-05-04 21:11:13","","","","",,,,,91,7.58,30,3,12,"A powerful method to aid in understanding the performance of parallel applications uses log or trace files containing time-stamped events and states (pairs of events). These trace files can be very large, often hundreds or even thousands of megabytes. Because of the cost of …"
91,"H Luu, M Winslett, W Gropp, R Ross, P Carns…","A multiplatform study of I/O behavior on petascale supercomputers",2015,"Proceedings of the 24th …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/2749246.2749269","https://scholar.google.com/scholar?cites=2416244284334489536&as_sdt=2005&sciodt=0,5&hl=en",66,"2020-05-04 21:11:13","","","","",,,,,91,18.20,15,6,5,"We examine the I/O behavior of thousands of supercomputing applications"" in the wild,"" by analyzing the Darshan logs of over a million jobs representing a combined total of six years of I/O behavior across three leading high-performance computing platforms. We mined these …"
90,"G Almási, C Archer, JG Castanos…","Design and implementation of message-passing services for the Blue Gene/L supercomputer",2005,"IBM Journal of …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/5388785/","https://scholar.google.com/scholar?cites=15996356694244526889&as_sdt=2005&sciodt=0,5&hl=en",62,"2020-05-04 21:11:13","","","","",,,,,90,6.00,23,4,15,"The Blue Gene®/L (BG/L) supercomputer, with 65,536 dual-processor compute nodes, was designed from the ground up to support efficient execution of massively parallel message-passing programs. Part of this support is an optimized implementation of the Message …"
88,"S Balay, K Buschelman, WD Gropp…","PETSc",2001,"See http://www. mcs …","wgropp.cs.illinois.edu","http://wgropp.cs.illinois.edu/bib/talks/tdata/2001/PETSc.pdf","https://scholar.google.com/scholar?cites=9891500524471136460&as_sdt=2005&sciodt=0,5&hl=en",64,"2020-05-04 21:11:13","PDF","","","",,,,,88,4.63,22,4,19,"• Developing parallel, non-trivial PDE solvers that deliver high performance is still difficult, and requires months (or even years) of concentrated effort.• PETSc is a toolkit that can ease these difficulties and reduce the development time, but it is not a black-box PDE solver nor a …"
85,"H Gahvari, AH Baker, M Schulz, UM Yang…","Modeling the performance of an algebraic multigrid cycle on HPC platforms",2011,"Proceedings of the …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/1995896.1995924","https://scholar.google.com/scholar?cites=15934041325588063030&as_sdt=2005&sciodt=0,5&hl=en",68,"2020-05-04 21:11:13","","","","",,,,,85,9.44,17,5,9,"Now that the performance of individual cores has plateaued, future supercomputers will depend upon increasing parallelism for performance. Processor counts are now in the hundreds of thousands for the largest machines and will soon be in the millions. There is an …"
84,"WD Gropp, DK Kaushik, DE Keyes…","Performance modeling and tuning of an unstructured mesh CFD application",2000,"SC'00: Proceedings of …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1592747/","https://scholar.google.com/scholar?cites=5697628162710414341&as_sdt=2005&sciodt=0,5&hl=en",67,"2020-05-04 21:11:13","","","","",,,,,84,4.20,21,4,20,"This paper describes performance tuning experiences with a three-dimensional unstructured grid Euler flow code from NASA, which we have reimplemented in the PETSc framework and ported to several large-scale machines, including the ASCI Red and Blue …"
83,"XC Cai, WD Gropp, DE Keyes","A comparison of some domain decomposition and ILU preconditioned iterative methods for nonsymmetric elliptic problems",1994,"Numerical Linear Algebra with …","Wiley Online Library","https://onlinelibrary.wiley.com/doi/abs/10.1002/nla.1680010504?casa_token=Lc5jGLzNjzcAAAAA:oC3B0D6KnwDd5hQiBkKOeFDBGhIXi9xspQ1fo8VD6CNE2HTpt0EEY1lFzeh8zMrU6bj8K80IaZG5jfuR","https://scholar.google.com/scholar?cites=13183641968070913920&as_sdt=2005&sciodt=0,5&hl=en",65,"2020-05-04 21:11:13","","","","",,,,,83,3.19,28,3,26,"In recent years, competitive domain‐decomposed preconditioned iterative techniques of Krylov‐Schwarz type have been developed for nonsymmetric linear elliptic systems. Such systems arise when convection‐diffusion‐reaction problems from computational fluid …"
83,"Y Chen, S Byna, XH Sun, R Thakur…","Hiding I/O latency with pre-execution prefetching for parallel applications",2008,"SC'08: Proceedings of …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/5213209/","https://scholar.google.com/scholar?cites=6079845674372834743&as_sdt=2005&sciodt=0,5&hl=en",69,"2020-05-04 21:11:13","","","","",,,,,83,6.92,17,5,12,"Parallel applications are usually able to achieve high computational performance but suffer from large latency in I/O accesses. I/O prefetching is an effective solution for masking the latency. Most of existing I/O prefetching techniques, however, are conservative and their …"
82,"P Bridges, N Doss, W Gropp, E Karrels, E Lusk…","Users' Guide to mpich, a Portable Implementation of MPI",1995,"Argonne National …","csd.uoc.gr","http://www.csd.uoc.gr/~hy555/mpi/mpich.guide.pdf","https://scholar.google.com/scholar?cites=3508073559438620881&as_sdt=2005&sciodt=0,5&hl=en",70,"2020-05-04 21:11:13","PDF","","","",,,,,82,3.28,14,6,25,"Abstract MPI (Message-Passing Interface) is a standard specification for message-passing libraries. mpich is a portable implementation of the full MPI specification for a wide variety of parallel computing environments. This paper describes how to build and run MPI programs …"
81,"T Hoefler, W Gropp, W Kramer…","Performance modeling for systematic performance tuning",2011,"SC'11: Proceedings of …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6114475/","https://scholar.google.com/scholar?cites=15798742743614982928&as_sdt=2005&sciodt=0,5&hl=en",71,"2020-05-04 21:11:13","","","","",,,,,81,9.00,20,4,9,"The performance of parallel scientific applications depends on many factors which are determined by the execution environment and the parallel application. Especially on large parallel systems, it is too expensive to explore the solution space with series of experiments …"
78,"W Gropp","Parallel computing and domain decomposition",1991,"","mcs.anl.gov","https://scholar.google.comftp://ftp.mcs.anl.gov/pub/tech_reports/reports/P257.pdf","https://scholar.google.com/scholar?cites=2281040074341212572&as_sdt=2005&sciodt=0,5&hl=en",75,"2020-05-04 21:11:13","BOOK","","","",,,,,78,2.69,78,1,29,"Domain decomposition techniques appear a natural way to make good use of parallel computers. In particular, these techniques divide a computation into a local part, which may be done without any interprocessor communication, and a part that involves communication …"
78,"A Bhatele, N Jain, WD Gropp, LV Kale","Avoiding hot-spots on two-level direct networks",2011,"Proceedings of 2011 …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/2063384.2063486","https://scholar.google.com/scholar?cites=13909195246446200022&as_sdt=2005&sciodt=0,5&hl=en",76,"2020-05-04 21:11:13","","","","",,,,,78,8.67,20,4,9,"ABSTRACT A low-diameter, fast interconnection network is going to be a prerequisite for building exascale machines. A two-level direct network has been proposed by several groups as a scalable design for future machines. IBM's PERCS topology and the dragonfly …"
78,"T Hoefler, J Dinan, R Thakur, B Barrett…","Remote memory access programming in MPI-3",2015,"ACM Transactions on …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/2780584","https://scholar.google.com/scholar?cites=2436589057611021390&as_sdt=2005&sciodt=0,5&hl=en",79,"2020-05-04 21:11:13","","","","",,,,,78,15.60,16,5,5,"The Message Passing Interface (MPI) 3.0 standard, introduced in September 2012, includes a significant update to the one-sided communication interface, also known as remote memory access (RMA). In particular, the interface has been extended to better support …"
77,"H Yu, RK Sahoo, C Howson, G Almasi…","High performance file I/O for the Blue Gene/L supercomputer",2006,"… Symposium on High …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1598125/","https://scholar.google.com/scholar?cites=11505915828996795852&as_sdt=2005&sciodt=0,5&hl=en",72,"2020-05-04 21:11:13","","","","",,,,,77,5.50,15,5,14,"Parallel I/O plays a crucial role for most data-intensive applications running on massively parallel systems like Blue Gene/L that provides the promise of delivering enormous computational capability. We designed and implemented a highly scalable parallel file I/O …"
75,"G Gopalakrishnan, RM Kirby, S Siegel…","Formal analysis of MPI-based parallel programs",2011,"Communications of the …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/2043174.2043194","https://scholar.google.com/scholar?cites=6369696160344887529&as_sdt=2005&sciodt=0,5&hl=en",77,"2020-05-04 21:11:13","","","","",,,,,75,8.33,19,4,9,"MosT ParaLLeL CoMPUTiNG applications in high- performance computing use the Message Passing Interface (MPI) API. Given the fundamental importance of parallel computing to science and engineering research, application correctness is paramount. MPI was originally developed …"
74,"WD Gropp, E Lusk","User's Guide for mpich, a Portable Implementation of MPI. Mathematics and Computer Science Division, Argonne National Laboratory, 1996",1996,"ANL-96/6","","","https://scholar.google.com/scholar?cites=8677607348572615231&as_sdt=2005&sciodt=0,5&hl=en",73,"2020-05-04 21:11:13","CITATION","","","",,,,,74,3.08,37,2,24,""
74,"WD Gropp, B Smith","Chameleon parallel programming tools users manual",1993,"","Technical Report ANL-93/23 …","","https://scholar.google.com/scholar?cites=10435719456172348476&as_sdt=2005&sciodt=0,5&hl=en",74,"2020-05-04 21:11:13","CITATION","","","",,,,,74,2.74,37,2,27,""
74,"W Gropp, E Lusk","A high-performance MPI implementation on a shared-memory vector supercomputer",1997,"Parallel Computing","Elsevier","https://www.sciencedirect.com/science/article/pii/S0167819196000622","https://scholar.google.com/scholar?cites=14502091156129166241&as_sdt=2005&sciodt=0,5&hl=en",78,"2020-05-04 21:11:13","","","","",,,,,74,3.22,37,2,23,"In this article we recount the sequence of steps by which MPICH, a high-performance, portable implementation of the Message-Passing Interface (MPI) standard, was ported to the NEC SX-4, a high-performance parallel supercomputer. Each step in the sequence raised …"
74,"P Balaji, D Buntinas, D Goodell, W Gropp…","MPI on millions of cores",2011,"Parallel Processing …","World Scientific","https://www.worldscientific.com/doi/abs/10.1142/S0129626411000060","https://scholar.google.com/scholar?cites=14248261499000290166&as_sdt=2005&sciodt=0,5&hl=en",81,"2020-05-04 21:11:13","","","","",,,,,74,8.22,15,5,9,"Petascale parallel computers with more than a million processing cores are expected to be available in a couple of years. Although MPI is the dominant programming interface today for large-scale systems that at the highest end already have close to 300,000 processors, a …"
73,"I Foster, W Gropp, R Stevens","The parallel scalability of the spectral transform method",1992,"Monthly Weather Review","journals.ametsoc.org","https://journals.ametsoc.org/doi/abs/10.1175/1520-0493(1992)120%3C0835%3ATPSOTS%3E2.0.CO%3B2","https://scholar.google.com/scholar?cites=13740109701614748844&as_sdt=2005&sciodt=0,5&hl=en",80,"2020-05-04 21:11:13","","","","",,,,,73,2.61,24,3,28,"This paper investigates the suitability of the spectral transform method for parallel implementation. The spectral transform method is a natural candidate for general circulation models (GCMs) designed to run on large-scale parallel computers due to the large number …"
73,"E Chan, R Van De Geijn, W Gropp…","Collective communication on architectures that support simultaneous communication over multiple links",2006,"Proceedings of the …","dl.acm.org","https://dl.acm.org/doi/abs/10.1145/1122971.1122975","https://scholar.google.com/scholar?cites=6316917745657329289&as_sdt=2005&sciodt=0,5&hl=en",82,"2020-05-04 21:11:13","","","","",,,,,73,5.21,18,4,14,"Traditional collective communication algorithms are designed with the assumption that a node can communicate with only one other node at a time. On new parallel architectures such as the IBM Blue Gene/L, a node can communicate with multiple nodes simultaneously …"
73,"P Balaji, D Buntinas, D Goodell, W Gropp…","PMI: A scalable parallel process-management interface for extreme-scale systems",2010,"European MPI Users' …","Springer","https://link.springer.com/chapter/10.1007/978-3-642-15646-5_4","https://scholar.google.com/scholar?cites=2435741381275426455&as_sdt=2005&sciodt=0,5&hl=en",87,"2020-05-04 21:11:13","","","","",,,,,73,7.30,15,5,10,"Parallel programming models on large-scale systems require a scalable system for managing the processes that make up the execution of a parallel program. The process-management system must be able to launch millions of processes quickly when starting a …"
72,"MJ Rashti, J Green, P Balaji, A Afsahi…","Multi-core and network aware MPI topology functions",2011,"European MPI Users' …","Springer","https://link.springer.com/chapter/10.1007/978-3-642-24449-0_8","https://scholar.google.com/scholar?cites=5989786721187424859&as_sdt=2005&sciodt=0,5&hl=en",88,"2020-05-04 21:11:13","","","","",,,,,72,8.00,14,5,9,"MPI standard offers a set of topology-aware interfaces that can be used to construct graph and Cartesian topologies for MPI applications. These interfaces have been mostly used for topology construction and not for performance improvement. To optimize the performance, in …"
71,"R Thakur, W Gropp, B Toonen","Optimizing the synchronization operations in message passing interface one-sided communication",2005,"The International Journal of …","journals.sagepub.com","https://journals.sagepub.com/doi/abs/10.1177/1094342005054258?casa_token=ow0msTAKyS8AAAAA:l8mpJtzhpY-iSgg0d70J3YnmXaY6vB4ebtP5q-lWaUswYJt2CAoptbrTh-1CWAl8OoaMEowKXAm1wQ","https://scholar.google.com/scholar?cites=13944872435458454003&as_sdt=2005&sciodt=0,5&hl=en",83,"2020-05-04 21:11:13","","","","",,,,,71,4.73,24,3,15,"One-sided communication in Message Passing Interface (MPI) requires the use of one of three different synchronization mechanisms, which indicate when the one-sided operation can be started and when the operation is completed. Efficient implementation of the …"
70,"D Buntinas, G Mercier, W Gropp","Data transfers between processes in an SMP system: Performance study and application to MPI",2006,"… International Conference on …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1690653/","https://scholar.google.com/scholar?cites=11216628495399944439&as_sdt=2005&sciodt=0,5&hl=en",85,"2020-05-04 21:11:13","","","","",,,,,70,5.00,23,3,14,"This paper focuses on the transfer of large data in SMP systems. Achieving good performance for intranode communication is critical for developing an efficient communication system, especially in the context of SMP clusters. We evaluate the …"
70,"W Gropp, B Smith","Scalable, extensible, and portable numerical libraries",1993,"Proceedings of Scalable Parallel Libraries …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/365579/","https://scholar.google.com/scholar?cites=1790106039823715153&as_sdt=2005&sciodt=0,5&hl=en",86,"2020-05-04 21:11:13","","","","",,,,,70,2.59,35,2,27,"Designing a scalable and portable numerical library requires consideration of many factors, including choice of parallel communication technology, data structures, and user interfaces. The PETSc library (Portable Extensible Tools for Scientific computing) makes use of modern …"
69,"P Balaji, D Buntinas, D Goodell…","Fine-grained multithreading support for hybrid threaded MPI programming",2010,"… Journal of High …","journals.sagepub.com","https://journals.sagepub.com/doi/abs/10.1177/1094342009360206?casa_token=KPPlI5D3DCgAAAAA:nyyNKXs0uFAdVn6GqMHPc92hzWOiwXyFmUeKMHnhO0rb9m8536zozq70yQlJJ_wEsDe6SojhmddpWg","https://scholar.google.com/scholar?cites=15122177600176921730&as_sdt=2005&sciodt=0,5&hl=en",89,"2020-05-04 21:11:13","","","","",,,,,69,6.90,17,4,10,"As high-end computing systems continue to grow in scale, recent advances in multi-and many-core architectures have pushed such growth toward more dense architectures, that is, more processing elements per physical node, rather than more physical nodes themselves …"
68,"R Ross, N Miller, WD Gropp","Implementing fast and reusable datatype processing",2003,"European Parallel Virtual Machine/Message …","Springer","https://link.springer.com/chapter/10.1007/978-3-540-39924-7_55","https://scholar.google.com/scholar?cites=8247350285629038540&as_sdt=2005&sciodt=0,5&hl=en",84,"2020-05-04 21:11:13","","","","",,,,,68,4.00,23,3,17,"Methods for describing structured data are a key aid in application development. The MPI standard defines a system for creating “MPI types” at run time and using these types when passing messages, performing RMA operations, and accessing data in files. Similar …"
66,"WD Gropp, DE Keyes","Domain decomposition on parallel computers",1989,"IMPACT of Computing in Science and Engineering","Elsevier","https://www.sciencedirect.com/science/article/pii/0899824889900037","https://scholar.google.com/scholar?cites=14663741109467868030&as_sdt=2005&sciodt=0,5&hl=en",90,"2020-05-04 21:11:13","","","","",,,,,66,2.13,33,2,31,"We consider the application of domain decomposition techniques to the solution of sparse linear systems arising from implicit PDE discretizations on parallel computers. Representatives of two popular MIMD architectures, message passing (the Intel iPSC/2-SX) …"
66,"WD Gropp","Learning from the success of MPI",2001,"International Conference on High-Performance …","Springer","https://link.springer.com/chapter/10.1007/3-540-45307-5_8","https://scholar.google.com/scholar?cites=12311008515872447110&as_sdt=2005&sciodt=0,5&hl=en",91,"2020-05-04 21:11:13","","","","",,,,,66,3.47,66,1,19,"Abstract The Message Passing Interface (MPI) has been extremely successful as a portable way to program high-performance parallel computers. This success has occurred in spite of the view of many that message passing is dificult and that other approaches, including …"
66,"J Cownie, W Gropp","A standard interface for debugger access to message queue information in MPI",1999,"European Parallel Virtual Machine/Message Passing …","Springer","https://link.springer.com/chapter/10.1007/3-540-48158-3_7","https://scholar.google.com/scholar?cites=333631921148330004&as_sdt=2005&sciodt=0,5&hl=en",92,"2020-05-04 21:11:13","","","","",,,,,66,3.14,33,2,21,"This paper discusses the design and implementation of an interface that allows a debugger to obtain the information necessary to display the contents of the MPI message queues. The design has been implemented in the TotalView debugger, and dynamic libraries that …"
66,"D Buntinas, G Mercier, W Gropp","Implementation and shared-memory evaluation of MPICH2 over the Nemesis communication subsystem",2006,"European Parallel Virtual Machine …","Springer","https://link.springer.com/chapter/10.1007/11846802_19","https://scholar.google.com/scholar?cites=14995575851466210924&as_sdt=2005&sciodt=0,5&hl=en",94,"2020-05-04 21:11:13","","","","",,,,,66,4.71,22,3,14,"This paper presents the implementation of MPICH2 over the Nemesis communication subsystem and the evaluation of its shared-memory performance. We describe design issues as well as some of the optimization techniques we employed. We conducted a …"
64,"WD Gropp","A test of moving mesh refinement for 2-D scalar hyperbolic problems",1980,"SIAM Journal on Scientific and Statistical Computing","SIAM","https://epubs.siam.org/doi/pdf/10.1137/0901012","https://scholar.google.com/scholar?cites=15727629264079019656&as_sdt=2005&sciodt=0,5&hl=en",93,"2020-05-04 21:11:13","","","","",,,,,64,1.60,64,1,40,"Abstract. We present an algorithm for numerically solving hyperbolic equations with moving shock fronts. The central idea is a moving, finer mesh which follows the shock. Computational results are presented. Key words, hyperbolic partial differential equations, finite differences, mesh …"
63,"R Butler, W Gropp, E Lusk","A scalable process-management environment for parallel programs",2000,"European Parallel Virtual Machine/Message …","Springer","https://link.springer.com/chapter/10.1007/3-540-45255-9_25","https://scholar.google.com/scholar?cites=17080401490381159279&as_sdt=2005&sciodt=0,5&hl=en",95,"2020-05-04 21:11:13","","","","",,,,,63,3.15,21,3,20,"We present a process management system for parallel programs such as those written using MPI. A primary goal of the system, which we call MPD (for multipurpose daemon), is to be scalable. By this we mean that startup of interactive parallel jobs comprising a thousand …"
60,"WD Gropp, DE Keyes","Complexity of parallel implementation of domain decomposition techniques for elliptic partial differential equations",1988,"SIAM Journal on Scientific and Statistical Computing","SIAM","https://epubs.siam.org/doi/abs/10.1137/0909020","https://scholar.google.com/scholar?cites=12877009772248465201&as_sdt=2005&sciodt=0,5&hl=en",96,"2020-05-04 21:11:13","","","","",,,,,60,1.88,30,2,32,"We discuss the parallel implementation of preconditioned conjugate gradient (PCG)-based domain decomposition techniques for self-adjoint elliptic partial differential equations in two dimensions on several architectures. The complexity of these methods is described on a …"
59,"W Gropp, E Lusk","MPICH Working Note: Creating a new MPICH device using the Channel interface DRAFT",1995,"","sunsite2.icm.edu.pl","https://scholar.google.comftp://sunsite2.icm.edu.pl/site/mpich/workingnote/newadi.ps","https://scholar.google.com/scholar?cites=6219772169052882363&as_sdt=2005&sciodt=0,5&hl=en",97,"2020-05-04 21:11:13","PS","","","",,,,,59,2.36,30,2,25,"The MPICH implementation of MPI uses a powerful and e cient layered approach to simplify porting MPI to new systems. One interface that can be used is the channel interface; this interface de nes a collection of simple data-transfer operations. This interface can adapt to …"
59,"A Roy, I Foster, W Gropp, N Karonis…","MPICH-GQ: Quality-of-service for message passing programs",2000,"SC'00: Proceedings …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/1592732/","https://scholar.google.com/scholar?cites=15817183078647518123&as_sdt=2005&sciodt=0,5&hl=en",98,"2020-05-04 21:11:13","","","","",,,,,59,2.95,12,5,20,"Parallel programmers typically assume that all resources required for a program's execution are dedicated to that purpose. However, in local and wide area networks, contention for shared networks, CPUs, and I/O systems can result in significant variations in availability …"
59,"W Gropp, R Thakur","Thread-safety in an MPI implementation: Requirements and analysis",2007,"Parallel Computing","Elsevier","https://www.sciencedirect.com/science/article/pii/S0167819107000889","https://scholar.google.com/scholar?cites=7021566434429583230&as_sdt=2005&sciodt=0,5&hl=en",99,"2020-05-04 21:11:13","","","","",,,,,59,4.54,30,2,13,"The MPI-2 Standard has carefully specified the interaction between MPI and user-created threads. The goal of this specification is to allow users to write multithreaded MPI programs while also allowing MPI implementations to deliver high performance. However, a simple …"
57,"B Shen, Y Li, K Nemeth, H Shang, Y Chae…","Electron injection by a nanowire in the bubble regime",2007,"Physics of …","aip.scitation.org","https://aip.scitation.org/doi/abs/10.1063/1.2728773","https://scholar.google.com/scholar?cites=88849821267019865&as_sdt=2005&sciodt=0,5&hl=en",100,"2020-05-04 21:11:13","","","","",,,,,57,4.38,10,6,13,"The triggering of wave-breaking in a three-dimensional laser plasma wake (bubble) is investigated. The Coulomb potential from a nanowire is used to disturb the wake field to initialize the wave-breaking. The electron acceleration becomes more stable and the laser …"
54,"W Gropp, E Lusk","Sowing MPICH: A case study in the dissemination of a portable environment for parallel scientific computing",1997,"The International Journal of …","journals.sagepub.com","https://journals.sagepub.com/doi/abs/10.1177/109434209701100204?casa_token=EIzrwtxYctgAAAAA:cJxWV_qAEAE4xLHjWITM0SfNDqah3yhnkfWAvy6Sf1QFwFDJ9VBCiE8yCf1vAtxtI9hVqiaFv3A_VQ","https://scholar.google.com/scholar?cites=12096420662191726971&as_sdt=2005&sciodt=0,5&hl=en",101,"2020-05-04 21:11:13","","","","",,,,,54,2.35,27,2,23,"MPICH is an implementation of the MPI specification for a standard message-passing library interface. This paper focuses on the lessons learned from preparing MPICH for diverse parallel computing environments. These lessons include how to prepare software for …"
54,"W Gropp, E Lusk, A Skjellum","Using MPI: portable parallel programming with the message-passing interface. Scientific and engineering computation",1994,"","MIT Press, Cambridge, MA, USA","","https://scholar.google.com/scholar?cites=10195144952762279648&as_sdt=2005&sciodt=0,5&hl=en",108,"2020-05-04 21:11:13","CITATION","","","",,,,,54,2.08,18,3,26,""
53,"W Gropp, E Lusk","A. Skjellum. Using MPI. Portable Parallel Programming with the Message-Passing Interface",1999,"","The MIT Press, Cambridge …","","https://scholar.google.com/scholar?cites=16236972948046638542&as_sdt=2005&sciodt=0,5&hl=en",102,"2020-05-04 21:11:13","CITATION","","","",,,,,53,2.52,27,2,21,""
53,"WD Gropp, DE Keyes","Domain decomposition methods in computational fluid dynamics",1992,"… journal for numerical methods in fluids","Wiley Online Library","https://onlinelibrary.wiley.com/doi/abs/10.1002/fld.1650140203?casa_token=MqpCj6ZO2JYAAAAA:VboDgC0SUzZjkAVaGkjgZjhHmLVK0tvYeqMinl0ni1FDcePN3A4sF3ixah2eKJESfHOwtSkgHI6b_rb2","https://scholar.google.com/scholar?cites=16471337623112620263&as_sdt=2005&sciodt=0,5&hl=en",104,"2020-05-04 21:11:13","","","","",,,,,53,1.89,27,2,28,"The divide‐and‐conquer paradigm of iterative domain decomposition or substructuring has become a practical tool in computational fluid dynamics applications because of its flexibility in accommodating adaptive refinement through locally uniform (or quasi‐uniform) grids, its …"
53,"W Gropp, E Lusk","Dynamic process management in an MPI setting",1995,"… . Seventh IEEE Symposium on Parallel and …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/530729/","https://scholar.google.com/scholar?cites=6478413455262525039&as_sdt=2005&sciodt=0,5&hl=en",105,"2020-05-04 21:11:13","","","","",,,,,53,2.12,27,2,25,"We describe an architecture for the runtime environment for parallel applications as prelude to describing how parallel applications might interface to their environment in a portable way. We propose extensions to the Message-Passing Interface (MPI) Standard that provide …"
52,"WD Gropp","Local uniform mesh refinement with moving grids",1987,"SIAM journal on scientific and statistical computing","SIAM","https://epubs.siam.org/doi/abs/10.1137/0908036","https://scholar.google.com/scholar?cites=678550396476162720&as_sdt=2005&sciodt=0,5&hl=en",103,"2020-05-04 21:11:13","","","","",,,,,52,1.58,52,1,33,"Local Uniform Mesh Refinement (LUMR) is a powerful technique for solving hyperbolic partial differential equations. However, many problems contain regions where numerical dispersion is very large, such as steep fronts. In these regions, mesh refinement is not very …"
52,"W Gropp, E Lusk, D Swider","Improving the performance of MPI derived datatypes",1999,"Proceedings of the Third MPI Developer's …","mcs.anl.gov","https://www.mcs.anl.gov/papers/MPIDC99.pdf","https://scholar.google.com/scholar?cites=14224753455308512229&as_sdt=2005&sciodt=0,5&hl=en",106,"2020-05-04 21:11:13","PDF","","","",,,,,52,2.48,17,3,21,"Abstract The Message Passing Interface (MPI) standard provides a powerful mechanism for describing non-contiguous memory locations: derived datatypes. In addition, MPI derived datatypes have a key role in the MPI-2 I/O operations. In principle, MPI derived datatypes …"
50,"W Gropp, E Lusk, A Skjellum","Portable Parallel Programming with the Message-Passing Interface, 1994",1994,"MIT Press, 0-262-57104-8","","","https://scholar.google.com/scholar?cites=12681516075101164559&as_sdt=2005&sciodt=0,5&hl=en",107,"2020-05-04 21:11:13","CITATION","","","",,,,,50,1.92,17,3,26,""
50,"W Gropp","Tutorial on mpi: The message-passing interface",2009,"… and Computer Science Division Argonne National …","polaris.cs.uiuc.edu","http://polaris.cs.uiuc.edu/~padua/cs320/mpi/tutorial.pdf","https://scholar.google.com/scholar?cites=1052466401569804323&as_sdt=2005&sciodt=0,5&hl=en",109,"2020-05-04 21:11:13","PDF","","","",,,,,50,4.55,50,1,11,"Page 1. Tutorial on MPI: The Message-Passing Interface William Gropp A R G O N N E N A TIONAL LABO R A T O R Y U N IV E R SITY OF CHI C A G O • • Mathematics and Computer Science Division Argonne National Laboratory Argonne, IL 60439 gropp@mcs.anl.gov 1 Page …"
50,"R Thakur, W Gropp","Test suite for evaluating performance of MPI implementations that support MPI_THREAD_MULTIPLE",2007,"European Parallel Virtual Machine/Message Passing …","Springer","https://link.springer.com/chapter/10.1007/978-3-540-75416-9_13","https://scholar.google.com/scholar?cites=10948286969433410738&as_sdt=2005&sciodt=0,5&hl=en",110,"2020-05-04 21:11:13","","","","",,,,,50,3.85,25,2,13,"MPI implementations that support the highest level of thread safety for user programs, MPI_THREAD_MULTIPLE, are becoming widely available. Users often expect that different threads can execute independently and that the MPI implementation can provide the …"
48,"S Balay, W Gropp, LC McInnes, B Smith","The portable, extensible toolkit for scientific computation",2005,"Argonne National Laboratory","","","https://scholar.google.com/scholar?cites=3650704505038784978&as_sdt=2005&sciodt=0,5&hl=en",111,"2020-05-04 21:11:13","CITATION","","","",,,,,48,3.20,12,4,15,""
48,"A Chan, W Gropp, E Lusk","User's guide for mpe extensions for mpi programs",1998,"","bh0.physics.ubc.ca","https://scholar.google.comftp://bh0.physics.ubc.ca/pub/pgi-cdk-5.2-2/linux86/5.2/cdk/mpich/doc/mpeman.pdf","https://scholar.google.com/scholar?cites=3817865362665457749&as_sdt=2005&sciodt=0,5&hl=en",112,"2020-05-04 21:11:13","PDF","","","",,,,,48,2.18,16,3,22,"The MPE extensions provide a number of useful facilites for MPI programmers. These include several profiling libraries to collect information on MPI programs, including logfiles for post-mortum visualization and real-time animation. Also included are routines to provide …"
48,"R Thakur, W Gropp","Test suite for evaluating performance of multithreaded MPI communication",2009,"Parallel Computing","Elsevier","https://www.sciencedirect.com/science/article/pii/S0167819109000143","https://scholar.google.com/scholar?cites=1540407683854507453&as_sdt=2005&sciodt=0,5&hl=en",114,"2020-05-04 21:11:13","","","","",,,,,48,4.36,24,2,11,"As parallel systems are commonly being built out of increasingly large multicore chips, application programmers are exploring the use of hybrid programming models combining MPI across nodes and multithreading within a node. Many MPI implementations, however …"
47,"W Gropp, E Lusk, D Ashton, P Balaji, D Buntinas…","MPICH2 User's Guide Version 1.0. 7 Mathematics and Computer Science Division Argonne National Laboratory",2008,"","sites.google.com","https://sites.google.com/site/sdypunsl/mpich2-1.0.8-userguide.pdf","https://scholar.google.com/scholar?cites=16840907023899745637&as_sdt=2005&sciodt=0,5&hl=en",113,"2020-05-04 21:11:13","PDF","","","",,,,,47,3.92,8,6,12,"This manual assumes that MPICH2 has already been installed. For instructions on how to install MPICH2, see the MPICH2 Installer's Guide, or the README in the top-level MPICH2 directory. This manual explains how to compile, link, and run MPI applications, and use …"
47,"H Zhu, D Goodell, W Gropp, R Thakur","Hierarchical collectives in mpich2",2009,"European Parallel Virtual Machine …","Springer","https://link.springer.com/chapter/10.1007/978-3-642-03770-2_41","https://scholar.google.com/scholar?cites=15674127217175426446&as_sdt=2005&sciodt=0,5&hl=en",117,"2020-05-04 21:11:13","","","","",,,,,47,4.27,12,4,11,"Most parallel systems on which MPI is used are now hierarchical, such as systems with SMP nodes. Many papers have shown algorithms that exploit shared memory to optimize collective operations to good effect. But how much of the performance benefit comes from …"
46,"WD Gropp, DE Keyes","Domain decomposition with local mesh refinement",1992,"SIAM journal on scientific and statistical computing","SIAM","https://epubs.siam.org/doi/abs/10.1137/0913057","https://scholar.google.com/scholar?cites=6461002854818398366&as_sdt=2005&sciodt=0,5&hl=en",115,"2020-05-04 21:11:13","","","","",,,,,46,1.64,23,2,28,"A preconditioned Krylov iterative algorithm based on domain decomposition for linear systems arising from implicit finite-difference or finite-element discretizations of partial differential equation problems requiring local mesh refinement is described. To keep data …"
46,"W Gropp, R Thakur","Issues in developing a thread-safe MPI implementation",2006,"European Parallel Virtual Machine/Message Passing …","Springer","https://link.springer.com/chapter/10.1007/11846802_11","https://scholar.google.com/scholar?cites=5913101324098420961&as_sdt=2005&sciodt=0,5&hl=en",116,"2020-05-04 21:11:13","","","","",,,,,46,3.29,23,2,14,"The MPI-2 Standard has carefully specified the interaction between MPI and user-created threads, with the goal of enabling users to write multithreaded programs while also enabling MPI implementations to deliver high performance. In this paper, we describe and analyze …"
45,"Y Chen, XH Sun, R Thakur, PC Roth…","LACIO: A new collective I/O strategy for parallel I/O systems",2011,"… International Parallel & …","ieeexplore.ieee.org","https://ieeexplore.ieee.org/abstract/document/6012889/","https://scholar.google.com/scholar?cites=2030669269651192201&as_sdt=2005&sciodt=0,5&hl=en",118,"2020-05-04 21:11:13","","","","",,,,,45,5.00,9,5,9,"Parallel applications benefit considerably from the rapid advance of processor architectures and the available massive computational capability, but their performance suffers from large latency of I/O accesses. The poor I/O performance has been attributed as a critical cause of …"
44,"W Gropp, S Huss-Lederman, A Lumsdaine, E Lusk…","MPI the Complete Reference: The MPI-2 Extensions, Vol. 2",1998,"","MIT Press","","https://scholar.google.com/scholar?cites=11254024357163774801&as_sdt=2005&sciodt=0,5&hl=en",119,"2020-05-04 21:11:13","CITATION","","","",,,,,44,2.00,9,5,22,""
43,"B Bode, M Butler, T Dunning, T Hoeer…","The Blue Waters super-system for super-science",2013,"Contemporary High …","experts.illinois.edu","https://experts.illinois.edu/en/publications/the-blue-waters-super-system-for-super-science","https://scholar.google.com/scholar?cites=4711425724031318747&as_sdt=2005&sciodt=0,5&hl=en",120,"2020-05-04 21:11:13","","","","",,,,,43,6.14,9,5,7,"Blue Waters is a very well-balanced sustained petascale system being deployed into the National Science Foundation (NSF) Office of Cyber Infrastructure portfolio in 2012 for a diverse range of unique science and engineering challenges that require huge amounts of …"
